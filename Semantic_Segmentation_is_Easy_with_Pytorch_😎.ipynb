{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 1834160,
          "sourceType": "datasetVersion",
          "datasetId": 333968
        }
      ],
      "dockerImageVersionId": 30060,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "Semantic Segmentation is Easy with Pytorch ðŸ˜Ž",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shubibees/img_container/blob/main/Semantic_Segmentation_is_Easy_with_Pytorch_%F0%9F%98%8E.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'semantic-drone-dataset:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F333968%2F1834160%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240513%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240513T072344Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D6e2d69b822c0e085a2df98ac8022635d09d28aa7ecc17b9bc70ae20cdd724a42c7954d43c8941d9f503777f6a4e67b1b9b93c9d9999863cbc291f06e28fdaa8e27d264f49da0f02ebd38c156cd0094787a589eb658baccffbda1e2b46b55de79a801bed6831bdf2c86675f40a5dcee90ae407c71dc0576c643943c362e6df9982222e253f419296c89d2e89d8668694f8d2618ccab0c6f7fe41acf11741f0be4656060b2f1baa4765dfabb952e7a5aaf8baf84e95d048dc252860f8e7b167006da1b504f0297693f3de6b62fe4ca5b0a8e5e5dcfe637b9b1cb9f3f563c39432639cc05c14686c58050dc993f634789baeb2f9dccdcea08044922b4d6ad85cd95'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gpz9T161gyF",
        "outputId": "c5a90350-2220-4c4d-bdde-1e4d00e850a0"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading semantic-drone-dataset, 4174531957 bytes compressed\n",
            "[==================================================] 4174531957 bytes downloaded\n",
            "Downloaded and uncompressed: semantic-drone-dataset\n",
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What is Semantic Segmentation?\n",
        "Semantic segmentation refers to the process of linking each pixel in an image to a class label. These labels could include a person, car, flower, piece of furniture, etc., just to mention a few.\n",
        "We can think of semantic segmentation as image classification at a pixel level. For example, in an image that has many cars, segmentation will label all the objects as car objects. However, a separate class of models known as instance segmentation is able to label the separate instances where an object appears in an image. This kind of segmentation can be very useful in applications that are used to count the number of objects, such as counting the amount of foot traffic in a mall."
      ],
      "metadata": {
        "id": "ffjam0p-1gyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Please upvote the kernel if you found it insightful!"
      ],
      "metadata": {
        "id": "ZTQJhn7Z1gyK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "l5i3N-weKP6-",
        "papermill": {
          "duration": 0.022866,
          "end_time": "2021-02-18T10:06:03.865074",
          "exception": false,
          "start_time": "2021-02-18T10:06:03.842208",
          "status": "completed"
        },
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms as T\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import albumentations as A\n",
        "\n",
        "import time\n",
        "import os\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "!pip install -q segmentation-models-pytorch\n",
        "!pip install -q torchsummary\n",
        "\n",
        "from torchsummary import summary\n",
        "import segmentation_models_pytorch as smp\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "kFSYoYRqJSfB",
        "papermill": {
          "duration": 23.025453,
          "end_time": "2021-02-18T10:06:26.911588",
          "exception": false,
          "start_time": "2021-02-18T10:06:03.886135",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-02-24T07:45:37.433144Z",
          "iopub.execute_input": "2024-02-24T07:45:37.433557Z",
          "iopub.status.idle": "2024-02-24T07:46:03.847217Z",
          "shell.execute_reply.started": "2024-02-24T07:45:37.433469Z",
          "shell.execute_reply": "2024-02-24T07:46:03.846329Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad795a1b-d149-4b58-f3ef-94b1948f76ee"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/106.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”\u001b[0m \u001b[32m102.4/106.7 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/58.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "1_HWVOdhJSfP",
        "papermill": {
          "duration": 0.026783,
          "end_time": "2021-02-18T10:06:26.966143",
          "exception": false,
          "start_time": "2021-02-18T10:06:26.93936",
          "status": "completed"
        },
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_PATH = 'kaggle/input/semantic-drone-dataset/dataset/semantic_drone_dataset/original_images/'\n",
        "MASK_PATH = '../input/semantic-drone-dataset/dataset/semantic_drone_dataset/label_images_semantic/'"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.033799,
          "end_time": "2021-02-18T10:06:27.027862",
          "exception": false,
          "start_time": "2021-02-18T10:06:26.994063",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-02-24T07:46:26.41717Z",
          "iopub.execute_input": "2024-02-24T07:46:26.417532Z",
          "iopub.status.idle": "2024-02-24T07:46:26.421426Z",
          "shell.execute_reply.started": "2024-02-24T07:46:26.417489Z",
          "shell.execute_reply": "2024-02-24T07:46:26.420275Z"
        },
        "trusted": true,
        "id": "kdJgXSkJ1gyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_classes = 23\n",
        "\n",
        "def create_df():\n",
        "    name = []\n",
        "    for dirname, _, filenames in os.walk(IMAGE_PATH):\n",
        "        for filename in filenames:\n",
        "            name.append(filename.split('.')[0])\n",
        "\n",
        "    return pd.DataFrame({'id': name}, index = np.arange(0, len(name)))\n",
        "\n",
        "df = create_df()\n",
        "print('Total Images: ', len(df))"
      ],
      "metadata": {
        "id": "gmPIy2ZFJSfQ",
        "papermill": {
          "duration": 0.157328,
          "end_time": "2021-02-18T10:06:27.211938",
          "exception": false,
          "start_time": "2021-02-18T10:06:27.05461",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-02-24T07:46:27.815247Z",
          "iopub.execute_input": "2024-02-24T07:46:27.815687Z",
          "iopub.status.idle": "2024-02-24T07:46:27.884607Z",
          "shell.execute_reply.started": "2024-02-24T07:46:27.815634Z",
          "shell.execute_reply": "2024-02-24T07:46:27.883688Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#split data\n",
        "X_trainval, X_test = train_test_split(df['id'].values, test_size=0.1, random_state=19)\n",
        "X_train, X_val = train_test_split(X_trainval, test_size=0.15, random_state=19)\n",
        "\n",
        "print('Train Size   : ', len(X_train))\n",
        "print('Val Size     : ', len(X_val))\n",
        "print('Test Size    : ', len(X_test))"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.045372,
          "end_time": "2021-02-18T10:06:27.28512",
          "exception": false,
          "start_time": "2021-02-18T10:06:27.239748",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-02-24T07:46:29.863329Z",
          "iopub.execute_input": "2024-02-24T07:46:29.863687Z",
          "iopub.status.idle": "2024-02-24T07:46:29.876265Z",
          "shell.execute_reply.started": "2024-02-24T07:46:29.863656Z",
          "shell.execute_reply": "2024-02-24T07:46:29.875395Z"
        },
        "trusted": true,
        "id": "Psz4oVqW1gyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = Image.open(IMAGE_PATH + df['id'][100] + '.jpg')\n",
        "mask = Image.open(MASK_PATH + df['id'][100] + '.png')\n",
        "print('Image Size', np.asarray(img).shape)\n",
        "print('Mask Size', np.asarray(mask).shape)\n",
        "\n",
        "\n",
        "plt.imshow(img)\n",
        "plt.imshow(mask, alpha=0.6)\n",
        "plt.title('Picture with Mask Appplied')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-uXF6vetJSff",
        "papermill": {
          "duration": 4.280771,
          "end_time": "2021-02-18T10:06:31.595115",
          "exception": false,
          "start_time": "2021-02-18T10:06:27.314344",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-02-24T07:46:33.56772Z",
          "iopub.execute_input": "2024-02-24T07:46:33.568187Z",
          "iopub.status.idle": "2024-02-24T07:46:37.35563Z",
          "shell.execute_reply.started": "2024-02-24T07:46:33.568141Z",
          "shell.execute_reply": "2024-02-24T07:46:37.354826Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "dkjFEoe7JSfo",
        "papermill": {
          "duration": 0.030107,
          "end_time": "2021-02-18T10:06:31.656378",
          "exception": false,
          "start_time": "2021-02-18T10:06:31.626271",
          "status": "completed"
        },
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DroneDataset(Dataset):\n",
        "\n",
        "    def __init__(self, img_path, mask_path, X, mean, std, transform=None, patch=False):\n",
        "        self.img_path = img_path\n",
        "        self.mask_path = mask_path\n",
        "        self.X = X\n",
        "        self.transform = transform\n",
        "        self.patches = patch\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = cv2.imread(self.img_path + self.X[idx] + '.jpg')\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        mask = cv2.imread(self.mask_path + self.X[idx] + '.png', cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        if self.transform is not None:\n",
        "            aug = self.transform(image=img, mask=mask)\n",
        "            img = Image.fromarray(aug['image'])\n",
        "            mask = aug['mask']\n",
        "\n",
        "        if self.transform is None:\n",
        "            img = Image.fromarray(img)\n",
        "\n",
        "        t = T.Compose([T.ToTensor(), T.Normalize(self.mean, self.std)])\n",
        "        img = t(img)\n",
        "        mask = torch.from_numpy(mask).long()\n",
        "\n",
        "        if self.patches:\n",
        "            img, mask = self.tiles(img, mask)\n",
        "\n",
        "        return img, mask\n",
        "\n",
        "    def tiles(self, img, mask):\n",
        "\n",
        "        img_patches = img.unfold(1, 512, 512).unfold(2, 768, 768)\n",
        "        img_patches  = img_patches.contiguous().view(3,-1, 512, 768)\n",
        "        img_patches = img_patches.permute(1,0,2,3)\n",
        "\n",
        "        mask_patches = mask.unfold(0, 512, 512).unfold(1, 768, 768)\n",
        "        mask_patches = mask_patches.contiguous().view(-1, 512, 768)\n",
        "\n",
        "        return img_patches, mask_patches"
      ],
      "metadata": {
        "id": "yne-vteuJSfp",
        "papermill": {
          "duration": 0.045449,
          "end_time": "2021-02-18T10:06:31.732603",
          "exception": false,
          "start_time": "2021-02-18T10:06:31.687154",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-02-24T07:46:43.27716Z",
          "iopub.execute_input": "2024-02-24T07:46:43.277489Z",
          "iopub.status.idle": "2024-02-24T07:46:43.290189Z",
          "shell.execute_reply.started": "2024-02-24T07:46:43.277461Z",
          "shell.execute_reply": "2024-02-24T07:46:43.2893Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean=[0.485, 0.456, 0.406]\n",
        "std=[0.229, 0.224, 0.225]\n",
        "\n",
        "t_train = A.Compose([A.Resize(704, 1056, interpolation=cv2.INTER_NEAREST), A.HorizontalFlip(), A.VerticalFlip(),\n",
        "                     A.GridDistortion(p=0.2), A.RandomBrightnessContrast((0,0.5),(0,0.5)),\n",
        "                     A.GaussNoise()])\n",
        "\n",
        "t_val = A.Compose([A.Resize(704, 1056, interpolation=cv2.INTER_NEAREST), A.HorizontalFlip(),\n",
        "                   A.GridDistortion(p=0.2)])\n",
        "\n",
        "#datasets\n",
        "train_set = DroneDataset(IMAGE_PATH, MASK_PATH, X_train, mean, std, t_train, patch=False)\n",
        "val_set = DroneDataset(IMAGE_PATH, MASK_PATH, X_val, mean, std, t_val, patch=False)\n",
        "\n",
        "#dataloader\n",
        "batch_size= 3\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "CCL93_giJSft",
        "papermill": {
          "duration": 0.041706,
          "end_time": "2021-02-18T10:06:31.80439",
          "exception": false,
          "start_time": "2021-02-18T10:06:31.762684",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-02-24T07:46:52.884491Z",
          "iopub.execute_input": "2024-02-24T07:46:52.88484Z",
          "iopub.status.idle": "2024-02-24T07:46:52.893163Z",
          "shell.execute_reply.started": "2024-02-24T07:46:52.884811Z",
          "shell.execute_reply": "2024-02-24T07:46:52.892248Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import torch\n",
        "#test loader\n",
        "for batch_id, (x, y) in enumerate(tqdm(train_loader), start=1):\n",
        "    print(f\"Batch ID: {batch_id}, Input Shape: {x.shape}, Target Shape: {y.shape}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-24T07:47:43.592489Z",
          "iopub.execute_input": "2024-02-24T07:47:43.592848Z",
          "iopub.status.idle": "2024-02-24T07:51:03.329124Z",
          "shell.execute_reply.started": "2024-02-24T07:47:43.592817Z",
          "shell.execute_reply": "2024-02-24T07:51:03.328055Z"
        },
        "trusted": true,
        "id": "VHop_ASn1gyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "jJ-ZypiFJSgJ",
        "papermill": {
          "duration": 0.029797,
          "end_time": "2021-02-18T10:06:31.864199",
          "exception": false,
          "start_time": "2021-02-18T10:06:31.834402",
          "status": "completed"
        },
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = smp.Unet('mobilenet_v2', encoder_weights='imagenet', classes=23, activation=None, encoder_depth=5, decoder_channels=[256, 128, 64, 32, 16])"
      ],
      "metadata": {
        "id": "ZXb8nBmpJSgK",
        "papermill": {
          "duration": 0.637787,
          "end_time": "2021-02-18T10:06:32.532384",
          "exception": false,
          "start_time": "2021-02-18T10:06:31.894597",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-02-24T07:46:56.178163Z",
          "iopub.execute_input": "2024-02-24T07:46:56.178494Z",
          "iopub.status.idle": "2024-02-24T07:46:56.799294Z",
          "shell.execute_reply.started": "2024-02-24T07:46:56.178464Z",
          "shell.execute_reply": "2024-02-24T07:46:56.798498Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-02-18T10:06:32.60428Z",
          "iopub.status.busy": "2021-02-18T10:06:32.602994Z",
          "iopub.status.idle": "2021-02-18T10:06:32.606962Z",
          "shell.execute_reply": "2021-02-18T10:06:32.607359Z"
        },
        "id": "32nY_jBWJSgN",
        "papermill": {
          "duration": 0.043393,
          "end_time": "2021-02-18T10:06:32.607492",
          "exception": false,
          "start_time": "2021-02-18T10:06:32.564099",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "ncudHa0UJSgQ",
        "papermill": {
          "duration": 0.031715,
          "end_time": "2021-02-18T10:06:32.670851",
          "exception": false,
          "start_time": "2021-02-18T10:06:32.639136",
          "status": "completed"
        },
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pixel_accuracy(output, mask):\n",
        "    with torch.no_grad():\n",
        "        output = torch.argmax(F.softmax(output, dim=1), dim=1)\n",
        "        correct = torch.eq(output, mask).int()\n",
        "        accuracy = float(correct.sum()) / float(correct.numel())\n",
        "    return accuracy"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-02-18T10:06:32.740402Z",
          "iopub.status.busy": "2021-02-18T10:06:32.739666Z",
          "iopub.status.idle": "2021-02-18T10:06:32.742805Z",
          "shell.execute_reply": "2021-02-18T10:06:32.742209Z"
        },
        "papermill": {
          "duration": 0.039711,
          "end_time": "2021-02-18T10:06:32.742919",
          "exception": false,
          "start_time": "2021-02-18T10:06:32.703208",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "8v42JcXw1gyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mIoU(pred_mask, mask, smooth=1e-10, n_classes=23):\n",
        "    with torch.no_grad():\n",
        "        pred_mask = F.softmax(pred_mask, dim=1)\n",
        "        pred_mask = torch.argmax(pred_mask, dim=1)\n",
        "        pred_mask = pred_mask.contiguous().view(-1)\n",
        "        mask = mask.contiguous().view(-1)\n",
        "\n",
        "        iou_per_class = []\n",
        "        for clas in range(0, n_classes): #loop per pixel class\n",
        "            true_class = pred_mask == clas\n",
        "            true_label = mask == clas\n",
        "\n",
        "            if true_label.long().sum().item() == 0: #no exist label in this loop\n",
        "                iou_per_class.append(np.nan)\n",
        "            else:\n",
        "                intersect = torch.logical_and(true_class, true_label).sum().float().item()\n",
        "                union = torch.logical_or(true_class, true_label).sum().float().item()\n",
        "\n",
        "                iou = (intersect + smooth) / (union +smooth)\n",
        "                iou_per_class.append(iou)\n",
        "        return np.nanmean(iou_per_class)"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-02-18T10:06:32.824646Z",
          "iopub.status.busy": "2021-02-18T10:06:32.823648Z",
          "iopub.status.idle": "2021-02-18T10:06:32.826286Z",
          "shell.execute_reply": "2021-02-18T10:06:32.826674Z"
        },
        "id": "5cqfcLtOJSgS",
        "papermill": {
          "duration": 0.048322,
          "end_time": "2021-02-18T10:06:32.826838",
          "exception": false,
          "start_time": "2021-02-18T10:06:32.778516",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_lr(optimizer):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        return param_group['lr']\n",
        "\n",
        "def fit(epochs, model, train_loader, val_loader, criterion, optimizer, scheduler, patch=False):\n",
        "    torch.cuda.empty_cache()\n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "    val_iou = []; val_acc = []\n",
        "    train_iou = []; train_acc = []\n",
        "    lrs = []\n",
        "    min_loss = np.inf\n",
        "    decrease = 1 ; not_improve=0\n",
        "\n",
        "    model.to(device)\n",
        "    fit_time = time.time()\n",
        "    for e in range(epochs):\n",
        "        since = time.time()\n",
        "        running_loss = 0\n",
        "        iou_score = 0\n",
        "        accuracy = 0\n",
        "        #training loop\n",
        "        model.train()\n",
        "        for i, data in enumerate(tqdm(train_loader)):\n",
        "            #training phase\n",
        "            image_tiles, mask_tiles = data\n",
        "            if patch:\n",
        "                bs, n_tiles, c, h, w = image_tiles.size()\n",
        "\n",
        "                image_tiles = image_tiles.view(-1,c, h, w)\n",
        "                mask_tiles = mask_tiles.view(-1, h, w)\n",
        "\n",
        "            image = image_tiles.to(device); mask = mask_tiles.to(device);\n",
        "            #forward\n",
        "            output = model(image)\n",
        "            loss = criterion(output, mask)\n",
        "            #evaluation metrics\n",
        "            iou_score += mIoU(output, mask)\n",
        "            accuracy += pixel_accuracy(output, mask)\n",
        "            #backward\n",
        "            loss.backward()\n",
        "            optimizer.step() #update weight\n",
        "            optimizer.zero_grad() #reset gradient\n",
        "\n",
        "            #step the learning rate\n",
        "            lrs.append(get_lr(optimizer))\n",
        "            scheduler.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        else:\n",
        "            model.eval()\n",
        "            test_loss = 0\n",
        "            test_accuracy = 0\n",
        "            val_iou_score = 0\n",
        "            #validation loop\n",
        "            with torch.no_grad():\n",
        "                for i, data in enumerate(tqdm(val_loader)):\n",
        "                    #reshape to 9 patches from single image, delete batch size\n",
        "                    image_tiles, mask_tiles = data\n",
        "\n",
        "                    if patch:\n",
        "                        bs, n_tiles, c, h, w = image_tiles.size()\n",
        "\n",
        "                        image_tiles = image_tiles.view(-1,c, h, w)\n",
        "                        mask_tiles = mask_tiles.view(-1, h, w)\n",
        "\n",
        "                    image = image_tiles.to(device); mask = mask_tiles.to(device);\n",
        "                    output = model(image)\n",
        "                    #evaluation metrics\n",
        "                    val_iou_score +=  mIoU(output, mask)\n",
        "                    test_accuracy += pixel_accuracy(output, mask)\n",
        "                    #loss\n",
        "                    loss = criterion(output, mask)\n",
        "                    test_loss += loss.item()\n",
        "\n",
        "            #calculatio mean for each batch\n",
        "            train_losses.append(running_loss/len(train_loader))\n",
        "            test_losses.append(test_loss/len(val_loader))\n",
        "\n",
        "\n",
        "            if min_loss > (test_loss/len(val_loader)):\n",
        "                print('Loss Decreasing.. {:.3f} >> {:.3f} '.format(min_loss, (test_loss/len(val_loader))))\n",
        "                min_loss = (test_loss/len(val_loader))\n",
        "                decrease += 1\n",
        "                if decrease % 5 == 0:\n",
        "                    print('saving model...')\n",
        "                    torch.save(model, 'Unet-Mobilenet_v2_mIoU-{:.3f}.pt'.format(val_iou_score/len(val_loader)))\n",
        "\n",
        "\n",
        "            if (test_loss/len(val_loader)) > min_loss:\n",
        "                not_improve += 1\n",
        "                min_loss = (test_loss/len(val_loader))\n",
        "                print(f'Loss Not Decrease for {not_improve} time')\n",
        "                if not_improve == 7:\n",
        "                    print('Loss not decrease for 7 times, Stop Training')\n",
        "                    break\n",
        "\n",
        "            #iou\n",
        "            val_iou.append(val_iou_score/len(val_loader))\n",
        "            train_iou.append(iou_score/len(train_loader))\n",
        "            train_acc.append(accuracy/len(train_loader))\n",
        "            val_acc.append(test_accuracy/ len(val_loader))\n",
        "            print(\"Epoch:{}/{}..\".format(e+1, epochs),\n",
        "                  \"Train Loss: {:.3f}..\".format(running_loss/len(train_loader)),\n",
        "                  \"Val Loss: {:.3f}..\".format(test_loss/len(val_loader)),\n",
        "                  \"Train mIoU:{:.3f}..\".format(iou_score/len(train_loader)),\n",
        "                  \"Val mIoU: {:.3f}..\".format(val_iou_score/len(val_loader)),\n",
        "                  \"Train Acc:{:.3f}..\".format(accuracy/len(train_loader)),\n",
        "                  \"Val Acc:{:.3f}..\".format(test_accuracy/len(val_loader)),\n",
        "                  \"Time: {:.2f}m\".format((time.time()-since)/60))\n",
        "\n",
        "    history = {'train_loss' : train_losses, 'val_loss': test_losses,\n",
        "               'train_miou' :train_iou, 'val_miou':val_iou,\n",
        "               'train_acc' :train_acc, 'val_acc':val_acc,\n",
        "               'lrs': lrs}\n",
        "    print('Total time: {:.2f} m' .format((time.time()- fit_time)/60))\n",
        "    return history"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-02-18T10:06:32.899945Z",
          "iopub.status.busy": "2021-02-18T10:06:32.899029Z",
          "iopub.status.idle": "2021-02-18T10:06:32.922271Z",
          "shell.execute_reply": "2021-02-18T10:06:32.921673Z"
        },
        "id": "8i9UIFUJJSgZ",
        "papermill": {
          "duration": 0.060048,
          "end_time": "2021-02-18T10:06:32.922403",
          "exception": false,
          "start_time": "2021-02-18T10:06:32.862355",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_lr = 1e-3\n",
        "epoch = 15\n",
        "weight_decay = 1e-4\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=max_lr, weight_decay=weight_decay)\n",
        "sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epoch,\n",
        "                                            steps_per_epoch=len(train_loader))\n",
        "\n",
        "history = fit(epoch, model, train_loader, val_loader, criterion, optimizer, sched)"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-02-18T10:06:33.004857Z",
          "iopub.status.busy": "2021-02-18T10:06:33.004322Z",
          "iopub.status.idle": "2021-02-18T11:11:14.818207Z",
          "shell.execute_reply": "2021-02-18T11:11:14.818842Z"
        },
        "id": "vo-VQwfJJSgg",
        "papermill": {
          "duration": 3881.864248,
          "end_time": "2021-02-18T11:11:14.819081",
          "exception": false,
          "start_time": "2021-02-18T10:06:32.954833",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, 'Unet-Mobilenet.pt')"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-02-18T11:11:14.942475Z",
          "iopub.status.busy": "2021-02-18T11:11:14.924135Z",
          "iopub.status.idle": "2021-02-18T11:11:15.016759Z",
          "shell.execute_reply": "2021-02-18T11:11:15.017446Z"
        },
        "id": "km58PT8qvJ4g",
        "papermill": {
          "duration": 0.15037,
          "end_time": "2021-02-18T11:11:15.01764",
          "exception": false,
          "start_time": "2021-02-18T11:11:14.86727",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_loss(history):\n",
        "    plt.plot(history['val_loss'], label='val', marker='o')\n",
        "    plt.plot( history['train_loss'], label='train', marker='o')\n",
        "    plt.title('Loss per epoch'); plt.ylabel('loss');\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(), plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "def plot_score(history):\n",
        "    plt.plot(history['train_miou'], label='train_mIoU', marker='*')\n",
        "    plt.plot(history['val_miou'], label='val_mIoU',  marker='*')\n",
        "    plt.title('Score per epoch'); plt.ylabel('mean IoU')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(), plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "def plot_acc(history):\n",
        "    plt.plot(history['train_acc'], label='train_accuracy', marker='*')\n",
        "    plt.plot(history['val_acc'], label='val_accuracy',  marker='*')\n",
        "    plt.title('Accuracy per epoch'); plt.ylabel('Accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(), plt.grid()\n",
        "    plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-02-18T11:11:15.562088Z",
          "iopub.status.busy": "2021-02-18T11:11:15.56023Z",
          "iopub.status.idle": "2021-02-18T11:11:15.56275Z",
          "shell.execute_reply": "2021-02-18T11:11:15.563389Z"
        },
        "id": "ojw74huJJSgn",
        "papermill": {
          "duration": 0.094126,
          "end_time": "2021-02-18T11:11:15.563574",
          "exception": false,
          "start_time": "2021-02-18T11:11:15.469448",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss(history)\n",
        "plot_score(history)\n",
        "plot_acc(history)"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-02-18T11:11:15.725962Z",
          "iopub.status.busy": "2021-02-18T11:11:15.725168Z",
          "iopub.status.idle": "2021-02-18T11:11:16.361868Z",
          "shell.execute_reply": "2021-02-18T11:11:16.361393Z"
        },
        "id": "KT-pRvoJJSgq",
        "papermill": {
          "duration": 0.71827,
          "end_time": "2021-02-18T11:11:16.361999",
          "exception": false,
          "start_time": "2021-02-18T11:11:15.643729",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "6BdSV7zxJSgu",
        "papermill": {
          "duration": 0.049339,
          "end_time": "2021-02-18T11:11:16.461916",
          "exception": false,
          "start_time": "2021-02-18T11:11:16.412577",
          "status": "completed"
        },
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DroneTestDataset(Dataset):\n",
        "\n",
        "    def __init__(self, img_path, mask_path, X, transform=None):\n",
        "        self.img_path = img_path\n",
        "        self.mask_path = mask_path\n",
        "        self.X = X\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = cv2.imread(self.img_path + self.X[idx] + '.jpg')\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        mask = cv2.imread(self.mask_path + self.X[idx] + '.png', cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        if self.transform is not None:\n",
        "            aug = self.transform(image=img, mask=mask)\n",
        "            img = Image.fromarray(aug['image'])\n",
        "            mask = aug['mask']\n",
        "\n",
        "        if self.transform is None:\n",
        "            img = Image.fromarray(img)\n",
        "\n",
        "        mask = torch.from_numpy(mask).long()\n",
        "\n",
        "        return img, mask\n",
        "\n",
        "\n",
        "t_test = A.Resize(768, 1152, interpolation=cv2.INTER_NEAREST)\n",
        "test_set = DroneTestDataset(IMAGE_PATH, MASK_PATH, X_test, transform=t_test)"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-02-18T11:11:16.570237Z",
          "iopub.status.busy": "2021-02-18T11:11:16.569485Z",
          "iopub.status.idle": "2021-02-18T11:11:16.57332Z",
          "shell.execute_reply": "2021-02-18T11:11:16.572904Z"
        },
        "id": "s9A82ZcL14-M",
        "papermill": {
          "duration": 0.06197,
          "end_time": "2021-02-18T11:11:16.573439",
          "exception": false,
          "start_time": "2021-02-18T11:11:16.511469",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Result"
      ],
      "metadata": {
        "id": "j0c6UnUz4gb6",
        "papermill": {
          "duration": 0.050775,
          "end_time": "2021-02-18T11:11:16.67452",
          "exception": false,
          "start_time": "2021-02-18T11:11:16.623745",
          "status": "completed"
        },
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_image_mask_miou(model, image, mask, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]):\n",
        "    model.eval()\n",
        "    t = T.Compose([T.ToTensor(), T.Normalize(mean, std)])\n",
        "    image = t(image)\n",
        "    model.to(device); image=image.to(device)\n",
        "    mask = mask.to(device)\n",
        "    with torch.no_grad():\n",
        "\n",
        "        image = image.unsqueeze(0)\n",
        "        mask = mask.unsqueeze(0)\n",
        "\n",
        "        output = model(image)\n",
        "        score = mIoU(output, mask)\n",
        "        masked = torch.argmax(output, dim=1)\n",
        "        masked = masked.cpu().squeeze(0)\n",
        "    return masked, score"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-02-18T11:11:16.783538Z",
          "iopub.status.busy": "2021-02-18T11:11:16.782798Z",
          "iopub.status.idle": "2021-02-18T11:11:16.785747Z",
          "shell.execute_reply": "2021-02-18T11:11:16.785316Z"
        },
        "papermill": {
          "duration": 0.060719,
          "end_time": "2021-02-18T11:11:16.785872",
          "exception": false,
          "start_time": "2021-02-18T11:11:16.725153",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "UJedJt4M1gyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_image_mask_pixel(model, image, mask, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]):\n",
        "    model.eval()\n",
        "    t = T.Compose([T.ToTensor(), T.Normalize(mean, std)])\n",
        "    image = t(image)\n",
        "    model.to(device); image=image.to(device)\n",
        "    mask = mask.to(device)\n",
        "    with torch.no_grad():\n",
        "\n",
        "        image = image.unsqueeze(0)\n",
        "        mask = mask.unsqueeze(0)\n",
        "\n",
        "        output = model(image)\n",
        "        acc = pixel_accuracy(output, mask)\n",
        "        masked = torch.argmax(output, dim=1)\n",
        "        masked = masked.cpu().squeeze(0)\n",
        "    return masked, acc"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-02-18T11:11:16.892351Z",
          "iopub.status.busy": "2021-02-18T11:11:16.891618Z",
          "iopub.status.idle": "2021-02-18T11:11:16.894757Z",
          "shell.execute_reply": "2021-02-18T11:11:16.895131Z"
        },
        "id": "ggsxFaduVz2O",
        "papermill": {
          "duration": 0.059442,
          "end_time": "2021-02-18T11:11:16.89527",
          "exception": false,
          "start_time": "2021-02-18T11:11:16.835828",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image, mask = test_set[3]\n",
        "pred_mask, score = predict_image_mask_miou(model, image, mask)"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-02-18T11:11:16.998584Z",
          "iopub.status.busy": "2021-02-18T11:11:16.998047Z",
          "iopub.status.idle": "2021-02-18T11:11:17.669531Z",
          "shell.execute_reply": "2021-02-18T11:11:17.668461Z"
        },
        "id": "ZPPKBax53Kj7",
        "papermill": {
          "duration": 0.725244,
          "end_time": "2021-02-18T11:11:17.669662",
          "exception": false,
          "start_time": "2021-02-18T11:11:16.944418",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def miou_score(model, test_set):\n",
        "    score_iou = []\n",
        "    for i in tqdm(range(len(test_set))):\n",
        "        img, mask = test_set[i]\n",
        "        pred_mask, score = predict_image_mask_miou(model, img, mask)\n",
        "        score_iou.append(score)\n",
        "    return score_iou"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-02-18T11:11:17.774602Z",
          "iopub.status.busy": "2021-02-18T11:11:17.773989Z",
          "iopub.status.idle": "2021-02-18T11:11:17.777419Z",
          "shell.execute_reply": "2021-02-18T11:11:17.776996Z"
        },
        "id": "-UY_OKGW-Zo5",
        "papermill": {
          "duration": 0.057861,
          "end_time": "2021-02-18T11:11:17.777536",
          "exception": false,
          "start_time": "2021-02-18T11:11:17.719675",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mob_miou = miou_score(model, test_set)"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-02-18T11:11:17.902935Z",
          "iopub.status.busy": "2021-02-18T11:11:17.901972Z",
          "iopub.status.idle": "2021-02-18T11:11:44.471364Z",
          "shell.execute_reply": "2021-02-18T11:11:44.470493Z"
        },
        "id": "DCa1A9y8zTbg",
        "papermill": {
          "duration": 26.64397,
          "end_time": "2021-02-18T11:11:44.471497",
          "exception": false,
          "start_time": "2021-02-18T11:11:17.827527",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pixel_acc(model, test_set):\n",
        "    accuracy = []\n",
        "    for i in tqdm(range(len(test_set))):\n",
        "        img, mask = test_set[i]\n",
        "        pred_mask, acc = predict_image_mask_pixel(model, img, mask)\n",
        "        accuracy.append(acc)\n",
        "    return accuracy"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-02-18T11:11:44.58043Z",
          "iopub.status.busy": "2021-02-18T11:11:44.578623Z",
          "iopub.status.idle": "2021-02-18T11:11:44.581014Z",
          "shell.execute_reply": "2021-02-18T11:11:44.581408Z"
        },
        "id": "LuexylyzXCmc",
        "papermill": {
          "duration": 0.058884,
          "end_time": "2021-02-18T11:11:44.581542",
          "exception": false,
          "start_time": "2021-02-18T11:11:44.522658",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mob_acc = pixel_acc(model, test_set)"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-02-18T11:11:44.713091Z",
          "iopub.status.busy": "2021-02-18T11:11:44.712183Z",
          "iopub.status.idle": "2021-02-18T11:12:10.040277Z",
          "shell.execute_reply": "2021-02-18T11:12:10.039836Z"
        },
        "id": "wIEZR3w4XTFL",
        "papermill": {
          "duration": 25.407116,
          "end_time": "2021-02-18T11:12:10.040411",
          "exception": false,
          "start_time": "2021-02-18T11:11:44.633295",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize=(20,10))\n",
        "ax1.imshow(image)\n",
        "ax1.set_title('Picture');\n",
        "\n",
        "ax2.imshow(mask)\n",
        "ax2.set_title('Ground truth')\n",
        "ax2.set_axis_off()\n",
        "\n",
        "ax3.imshow(pred_mask)\n",
        "ax3.set_title('UNet-MobileNet | mIoU {:.3f}'.format(score))\n",
        "ax3.set_axis_off()"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-02-18T11:12:10.162903Z",
          "iopub.status.busy": "2021-02-18T11:12:10.161911Z",
          "iopub.status.idle": "2021-02-18T11:12:10.715286Z",
          "shell.execute_reply": "2021-02-18T11:12:10.715682Z"
        },
        "id": "FV6xO9SLtSum",
        "papermill": {
          "duration": 0.624904,
          "end_time": "2021-02-18T11:12:10.715853",
          "exception": false,
          "start_time": "2021-02-18T11:12:10.090949",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image2, mask2 = test_set[4]\n",
        "pred_mask2, score2 = predict_image_mask_miou(model, image2, mask2)\n",
        "\n",
        "fig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize=(20,10))\n",
        "ax1.imshow(image2)\n",
        "ax1.set_title('Picture');\n",
        "\n",
        "ax2.imshow(mask2)\n",
        "ax2.set_title('Ground truth')\n",
        "ax2.set_axis_off()\n",
        "\n",
        "ax3.imshow(pred_mask2)\n",
        "ax3.set_title('UNet-MobileNet | mIoU {:.3f}'.format(score2))\n",
        "ax3.set_axis_off()"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-02-18T11:12:10.836981Z",
          "iopub.status.busy": "2021-02-18T11:12:10.83618Z",
          "iopub.status.idle": "2021-02-18T11:12:11.88577Z",
          "shell.execute_reply": "2021-02-18T11:12:11.886234Z"
        },
        "papermill": {
          "duration": 1.113059,
          "end_time": "2021-02-18T11:12:11.886384",
          "exception": false,
          "start_time": "2021-02-18T11:12:10.773325",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "jqm5Up2A1gyV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image3, mask3 = test_set[6]\n",
        "pred_mask3, score3 = predict_image_mask_miou(model, image3, mask3)\n",
        "\n",
        "fig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize=(20,10))\n",
        "ax1.imshow(image3)\n",
        "ax1.set_title('Picture');\n",
        "\n",
        "ax2.imshow(mask3)\n",
        "ax2.set_title('Ground truth')\n",
        "ax2.set_axis_off()\n",
        "\n",
        "ax3.imshow(pred_mask3)\n",
        "ax3.set_title('UNet-MobileNet | mIoU {:.3f}'.format(score3))\n",
        "ax3.set_axis_off()"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-02-18T11:12:12.022576Z",
          "iopub.status.busy": "2021-02-18T11:12:12.021816Z",
          "iopub.status.idle": "2021-02-18T11:12:13.061961Z",
          "shell.execute_reply": "2021-02-18T11:12:13.062372Z"
        },
        "papermill": {
          "duration": 1.110346,
          "end_time": "2021-02-18T11:12:13.062543",
          "exception": false,
          "start_time": "2021-02-18T11:12:11.952197",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "H3X-RUTp1gyV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Test Set mIoU', np.mean(mob_miou))"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-02-18T11:12:13.207789Z",
          "iopub.status.busy": "2021-02-18T11:12:13.207124Z",
          "iopub.status.idle": "2021-02-18T11:12:13.211749Z",
          "shell.execute_reply": "2021-02-18T11:12:13.211252Z"
        },
        "id": "xxTIX8P-JSh9",
        "papermill": {
          "duration": 0.079123,
          "end_time": "2021-02-18T11:12:13.21186",
          "exception": false,
          "start_time": "2021-02-18T11:12:13.132737",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Test Set Pixel Accuracy', np.mean(mob_acc))"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-02-18T11:12:13.356105Z",
          "iopub.status.busy": "2021-02-18T11:12:13.355397Z",
          "iopub.status.idle": "2021-02-18T11:12:13.361148Z",
          "shell.execute_reply": "2021-02-18T11:12:13.36053Z"
        },
        "id": "bcKnghXTXbAJ",
        "papermill": {
          "duration": 0.080048,
          "end_time": "2021-02-18T11:12:13.361311",
          "exception": false,
          "start_time": "2021-02-18T11:12:13.281263",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}